{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e672631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35a88c6",
   "metadata": {},
   "source": [
    "# Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cc8c027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>888</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>890</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0               0         0       3    male  22.0      1      0   7.2500   \n",
       "1               1         1       1  female  38.0      1      0  71.2833   \n",
       "2               2         1       3  female  26.0      0      0   7.9250   \n",
       "3               3         1       1  female  35.0      1      0  53.1000   \n",
       "4               4         0       3    male  35.0      0      0   8.0500   \n",
       "..            ...       ...     ...     ...   ...    ...    ...      ...   \n",
       "886           886         0       2    male  27.0      0      0  13.0000   \n",
       "887           887         1       1  female  19.0      0      0  30.0000   \n",
       "888           888         0       3  female   NaN      1      2  23.4500   \n",
       "889           889         1       1    male  26.0      0      0  30.0000   \n",
       "890           890         0       3    male  32.0      0      0   7.7500   \n",
       "\n",
       "    embarked   class deck  embark_town  alone  \n",
       "0          S   Third  NaN  Southampton      0  \n",
       "1          C   First    C    Cherbourg      0  \n",
       "2          S   Third  NaN  Southampton      1  \n",
       "3          S   First    C  Southampton      0  \n",
       "4          S   Third  NaN  Southampton      1  \n",
       "..       ...     ...  ...          ...    ...  \n",
       "886        S  Second  NaN  Southampton      1  \n",
       "887        S   First    B  Southampton      1  \n",
       "888        S   Third  NaN  Southampton      0  \n",
       "889        C   First    C    Cherbourg      1  \n",
       "890        Q   Third  NaN   Queenstown      1  \n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = acquire.get_titanic_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895e7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf0a26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.prep_titanic_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46afbae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "imputer = imputer.fit(train[['age']])\n",
    "train[['age']] = imputer.transform(train[['age']])\n",
    "validate[['age']] = imputer.transform(validate[['age']])\n",
    "test[['age']] = imputer.transform(test[['age']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef85cb91",
   "metadata": {},
   "source": [
    "## This would be where you explore your data\n",
    "\n",
    "    - adam has an excellent little exploration of 'no age' in his decicion tree exercise review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ca9fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 498 entries, 583 to 744\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   passenger_id             498 non-null    int64  \n",
      " 1   survived                 498 non-null    int64  \n",
      " 2   pclass                   498 non-null    int64  \n",
      " 3   sex                      498 non-null    object \n",
      " 4   age                      498 non-null    float64\n",
      " 5   sibsp                    498 non-null    int64  \n",
      " 6   parch                    498 non-null    int64  \n",
      " 7   fare                     498 non-null    float64\n",
      " 8   embark_town              498 non-null    object \n",
      " 9   alone                    498 non-null    int64  \n",
      " 10  baseline_prediction      498 non-null    int64  \n",
      " 11  sex_male                 498 non-null    uint8  \n",
      " 12  embark_town_Queenstown   498 non-null    uint8  \n",
      " 13  embark_town_Southampton  498 non-null    uint8  \n",
      "dtypes: float64(2), int64(7), object(2), uint8(3)\n",
      "memory usage: 48.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ae66546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 14), (214, 14), (179, 14))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc5e8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cf6d232",
   "metadata": {},
   "source": [
    "### 1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.\n",
    "\n",
    "        - the most prevalent class in your TRAINING dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "437d4764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e43655c",
   "metadata": {},
   "source": [
    "- the biggest value in the target variable is 0 (in other words, did not survive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a845bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['baseline_prediction'] = 0\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84030433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9829ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.76       307\n",
      "           1       0.00      0.00      0.00       191\n",
      "\n",
      "    accuracy                           0.62       498\n",
      "   macro avg       0.31      0.50      0.38       498\n",
      "weighted avg       0.38      0.62      0.47       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train.survived,train.baseline_prediction))\n",
    "\n",
    "# see the baseline accuracy in its classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b97437",
   "metadata": {},
   "source": [
    "- Baseline accuracy is 62%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75267ed2",
   "metadata": {},
   "source": [
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d2a9df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 498 entries, 583 to 744\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   passenger_id             498 non-null    int64  \n",
      " 1   survived                 498 non-null    int64  \n",
      " 2   pclass                   498 non-null    int64  \n",
      " 3   sex                      498 non-null    object \n",
      " 4   age                      498 non-null    float64\n",
      " 5   sibsp                    498 non-null    int64  \n",
      " 6   parch                    498 non-null    int64  \n",
      " 7   fare                     498 non-null    float64\n",
      " 8   embark_town              498 non-null    object \n",
      " 9   alone                    498 non-null    int64  \n",
      " 10  baseline_prediction      498 non-null    int64  \n",
      " 11  sex_male                 498 non-null    uint8  \n",
      " 12  embark_town_Queenstown   498 non-null    uint8  \n",
      " 13  embark_town_Southampton  498 non-null    uint8  \n",
      "dtypes: float64(2), int64(7), object(2), uint8(3)\n",
      "memory usage: 48.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93740726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the string features were causing problems with the DecisionTreeClassifier\n",
    "X_train = train.drop(columns=['survived', 'sex','passenger_id', 'embark_town'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived', 'sex','passenger_id','embark_town'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5c2317d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f59424b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass                     0\n",
       "age                        0\n",
       "sibsp                      0\n",
       "parch                      0\n",
       "fare                       0\n",
       "alone                      0\n",
       "baseline_prediction        0\n",
       "sex_male                   0\n",
       "embark_town_Queenstown     0\n",
       "embark_town_Southampton    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9d2b4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass                     0\n",
       "age                        0\n",
       "sibsp                      0\n",
       "parch                      0\n",
       "fare                       0\n",
       "alone                      0\n",
       "baseline_prediction        0\n",
       "sex_male                   0\n",
       "embark_town_Queenstown     0\n",
       "embark_town_Southampton    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# below, we the clf.fit function is telling me there are NaNs somewhere.  This show me 97 in 'age'\n",
    "X_train.isnull().sum()\n",
    "\n",
    "# i addressed this by imputing average ages two cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19bd9b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree object with desired hyper-parameters.\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "# clf = 'classifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a963e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model (i.e. apply the algorithm to your unique set of data so that the algorithm can identify a pattern)\n",
    "# model.fit(X, y)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f21abdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_decision_tree.pdf'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "from graphviz import Graph\n",
    "\n",
    "# there was initially an argument in here that was raising an error, something to do with X_train.classes_\n",
    "# we tood it out and things got better\n",
    "\n",
    "dot_data = export_graphviz(clf, feature_names= X_train.columns, rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f3bf0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction on train obeservations\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a328f4",
   "metadata": {},
   "source": [
    "### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8474ebc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65048544, 0.34951456],\n",
       "       [0.65048544, 0.34951456],\n",
       "       [0.65048544, 0.34951456],\n",
       "       [0.03225806, 0.96774194],\n",
       "       [0.03225806, 0.96774194]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "867a78dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.83\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ea4f278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[277,  30],\n",
       "       [ 57, 134]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5326649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d804fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual on the left, predicted on the top; 0 = perished, 1 = survived\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  277   30\n",
       "1   57  134"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top; 0 = perished, 1 = survived')\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "381f11a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       307\n",
      "           1       0.82      0.70      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.82      0.80      0.81       498\n",
      "weighted avg       0.82      0.83      0.82       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94869932",
   "metadata": {},
   "source": [
    "### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dda6410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isn't this what we did with the classification report? Yes, according to adam\n",
    "\n",
    "# True Positive rate = recall; false positive rate = precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb5356d",
   "metadata": {},
   "source": [
    "### 5. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8f362c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_decision_tree.pdf'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=4, random_state=123)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "dot_data = export_graphviz(clf, feature_names= X_train.columns, rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8246015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction on train obeservations\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76f61b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with max depth of 2\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.820433    0.760000  0.799197    0.790217      0.797255\n",
      "recall       0.863192    0.696335  0.799197    0.779764      0.799197\n",
      "f1-score     0.841270    0.726776  0.799197    0.784023      0.797358\n",
      "support    307.000000  191.000000  0.799197  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.831858    0.842767  0.835341    0.837313      0.836042\n",
      "recall       0.918567    0.701571  0.835341    0.810069      0.835341\n",
      "f1-score     0.873065    0.765714  0.835341    0.819390      0.831892\n",
      "support    307.000000  191.000000  0.835341  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 5\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.852410    0.855422  0.853414    0.853916      0.853565\n",
      "recall       0.921824    0.743455  0.853414    0.832640      0.853414\n",
      "f1-score     0.885759    0.795518  0.853414    0.840639      0.851149\n",
      "support    307.000000  191.000000  0.853414  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 6\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.838983    0.930556  0.865462    0.884769      0.874104\n",
      "recall       0.967427    0.701571  0.865462    0.834499      0.865462\n",
      "f1-score     0.898638    0.800000  0.865462    0.849319      0.860807\n",
      "support    307.000000  191.000000  0.865462  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 7\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.895570    0.868132  0.885542    0.881851      0.885046\n",
      "recall       0.921824    0.827225  0.885542    0.874525      0.885542\n",
      "f1-score     0.908507    0.847185  0.885542    0.877846      0.884988\n",
      "support    307.000000  191.000000  0.885542  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 8\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.872093    0.954545   0.89759    0.913319      0.903716\n",
      "recall       0.977199    0.769634   0.89759    0.873416      0.897590\n",
      "f1-score     0.921659    0.852174   0.89759    0.886916      0.895009\n",
      "support    307.000000  191.000000   0.89759  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 9\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.913580    0.936782  0.921687    0.925181      0.922479\n",
      "recall       0.964169    0.853403  0.921687    0.908786      0.921687\n",
      "f1-score     0.938193    0.893151  0.921687    0.915672      0.920918\n",
      "support    307.000000  191.000000  0.921687  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 10\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.933544    0.934066  0.933735    0.933805      0.933744\n",
      "recall       0.960912    0.890052  0.933735    0.925482      0.933735\n",
      "f1-score     0.947030    0.911528  0.933735    0.929279      0.933414\n",
      "support    307.000000  191.000000  0.933735  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 11\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.947040    0.983051  0.959839    0.965046      0.960852\n",
      "recall       0.990228    0.910995  0.959839    0.950611      0.959839\n",
      "f1-score     0.968153    0.945652  0.959839    0.956903      0.959523\n",
      "support    307.000000  191.000000  0.959839  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 12\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.962264    0.994444  0.973896    0.978354      0.974606\n",
      "recall       0.996743    0.937173  0.973896    0.966958      0.973896\n",
      "f1-score     0.979200    0.964960  0.973896    0.972080      0.973738\n",
      "support    307.000000  191.000000  0.973896  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 13\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.974603    1.000000  0.983936    0.987302      0.984344\n",
      "recall       1.000000    0.958115  0.983936    0.979058      0.983936\n",
      "f1-score     0.987138    0.978610  0.983936    0.982874      0.983867\n",
      "support    307.000000  191.000000  0.983936  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 14\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.990323    1.000000  0.993976    0.995161      0.994034\n",
      "recall       1.000000    0.984293  0.993976    0.992147      0.993976\n",
      "f1-score     0.995138    0.992084  0.993976    0.993611      0.993967\n",
      "support    307.000000  191.000000  0.993976  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 15\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.993528    1.000000  0.995984    0.996764      0.996010\n",
      "recall       1.000000    0.989529  0.995984    0.994764      0.995984\n",
      "f1-score     0.996753    0.994737  0.995984    0.995745      0.995980\n",
      "support    307.000000  191.000000  0.995984  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 16\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.993528    1.000000  0.995984    0.996764      0.996010\n",
      "recall       1.000000    0.989529  0.995984    0.994764      0.995984\n",
      "f1-score     0.996753    0.994737  0.995984    0.995745      0.995980\n",
      "support    307.000000  191.000000  0.995984  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 17\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.993528    1.000000  0.995984    0.996764      0.996010\n",
      "recall       1.000000    0.989529  0.995984    0.994764      0.995984\n",
      "f1-score     0.996753    0.994737  0.995984    0.995745      0.995980\n",
      "support    307.000000  191.000000  0.995984  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 18\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.993528    1.000000  0.995984    0.996764      0.996010\n",
      "recall       1.000000    0.989529  0.995984    0.994764      0.995984\n",
      "f1-score     0.996753    0.994737  0.995984    0.995745      0.995980\n",
      "support    307.000000  191.000000  0.995984  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 19\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.993528    1.000000  0.995984    0.996764      0.996010\n",
      "recall       1.000000    0.989529  0.995984    0.994764      0.995984\n",
      "f1-score     0.996753    0.994737  0.995984    0.995745      0.995980\n",
      "support    307.000000  191.000000  0.995984  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 20\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.993528    1.000000  0.995984    0.996764      0.996010\n",
      "recall       1.000000    0.989529  0.995984    0.994764      0.995984\n",
      "f1-score     0.996753    0.994737  0.995984    0.995745      0.995980\n",
      "support    307.000000  191.000000  0.995984  498.000000    498.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is Adam's 'for' loop\n",
    "for i in range(2, 21):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions = tree.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e995034",
   "metadata": {},
   "source": [
    "### 6. Which model performs better on your in-sample data?\n",
    "\n",
    "    - the max_depth 4 works about the same\n",
    "    - checking adam's code, 15+ max depth provides highest accuracy\n",
    "    - but we know that they are overfit somehow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a49d76",
   "metadata": {},
   "source": [
    "### Below is what I produced before the exercise review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1565c483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60674157, 0.39325843],\n",
       "       [0.60674157, 0.39325843],\n",
       "       [0.92857143, 0.07142857],\n",
       "       [0.07142857, 0.92857143],\n",
       "       [0.        , 1.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ada10770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.84\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ab497b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[282,  25],\n",
       "       [ 57, 134]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69b63991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "860ba93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual on the left, predicted on the top; 0 = perished, 1 = survived\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>282</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  282   25\n",
       "1   57  134"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top; 0 = perished, 1 = survived')\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d966d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       307\n",
      "           1       0.84      0.70      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.84      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a220e8",
   "metadata": {},
   "source": [
    "### 7. Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0dd5c10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_decision_tree.pdf'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "clf = clf.fit(X_validate, y_validate)\n",
    "dot_data = export_graphviz(clf, feature_names= X_validate.columns, rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be1e54c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction on train obeservations\n",
    "\n",
    "y_pred = clf.predict(X_validate)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "010ed091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86956522, 0.13043478],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.07894737, 0.92105263],\n",
       "       [0.07894737, 0.92105263]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59284fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.83\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "      .format(clf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c4e3a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127,   5],\n",
       "       [ 31,  51]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "confusion_matrix(y_validate, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78d1e2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d5e496a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual on the left, predicted on the top; 0 = perished, 1 = survived\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  127   5\n",
       "1   31  51"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top; 0 = perished, 1 = survived')\n",
    "pd.DataFrame(confusion_matrix(y_validate, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5154f8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.88       132\n",
      "           1       0.91      0.62      0.74        82\n",
      "\n",
      "    accuracy                           0.83       214\n",
      "   macro avg       0.86      0.79      0.81       214\n",
      "weighted avg       0.84      0.83      0.82       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "da0d09e6",
   "metadata": {},
   "source": [
    "### CLASSIFICATION REPORT FOR MAX_DEPTH = 3\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "f91df4d9",
   "metadata": {},
   "source": [
    " ### CLASSIFICATION REPORT FOR MAX_DEPTH = 4\n",
    " \n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b6a00c0b",
   "metadata": {},
   "source": [
    "### CLASSIFICATION REPORT FOR MAX_DEPTH = 5\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2305ecb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.026236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.040949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.853414</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.049675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.865462</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.075742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.885542</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.109841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.897590</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.112544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.113276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.933735</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.148688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.959839</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.165447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.973896</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.160811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.983936</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.198889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.213602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.206264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.206264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.206264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.206264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.206264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.206264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.206264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.206264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.206264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.206264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  validate_accuracy  difference\n",
       "0           2        0.799197           0.761682    0.037515\n",
       "1           3        0.825301           0.799065    0.026236\n",
       "2           4        0.835341           0.794393    0.040949\n",
       "3           5        0.853414           0.803738    0.049675\n",
       "4           6        0.865462           0.789720    0.075742\n",
       "5           7        0.885542           0.775701    0.109841\n",
       "6           8        0.897590           0.785047    0.112544\n",
       "7           9        0.921687           0.808411    0.113276\n",
       "8          10        0.933735           0.785047    0.148688\n",
       "9          11        0.959839           0.794393    0.165447\n",
       "10         12        0.973896           0.813084    0.160811\n",
       "11         13        0.983936           0.785047    0.198889\n",
       "12         14        0.993976           0.780374    0.213602\n",
       "13         15        0.995984           0.789720    0.206264\n",
       "14         16        0.995984           0.789720    0.206264\n",
       "15         17        0.995984           0.789720    0.206264\n",
       "16         18        0.995984           0.789720    0.206264\n",
       "17         19        0.995984           0.789720    0.206264\n",
       "18         20        0.995984           0.789720    0.206264\n",
       "19         21        0.995984           0.789720    0.206264\n",
       "20         22        0.995984           0.789720    0.206264\n",
       "21         23        0.995984           0.789720    0.206264\n",
       "22         24        0.995984           0.789720    0.206264"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adam's code for a nice, clean view:\n",
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(2, 25):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = tree.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = tree.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4286b69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.853414</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.049675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.026236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.040949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.865462</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.075742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  train_accuracy  validate_accuracy  difference\n",
       "3          5        0.853414           0.803738    0.049675\n",
       "1          3        0.825301           0.799065    0.026236\n",
       "2          4        0.835341           0.794393    0.040949\n",
       "4          6        0.865462           0.789720    0.075742\n",
       "0          2        0.799197           0.761682    0.037515"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here, we're comparing differences between the train and validate data sets\n",
    "# we're tossing any differences above a certain amount (.10) and ordering by difference as a tie-breaker\n",
    "df[df.difference <= 0.10].sort_values(by=['validate_accuracy', 'difference'], ascending = [False,True])\n",
    "\n",
    "# the best max_depth, following these criteria, is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e270d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cd472e3",
   "metadata": {},
   "source": [
    "# 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "\n",
    "\n",
    "### baseline accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7f611f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8482a91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth = 10, )\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e122c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = rf.fit(X_train, y_train)\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f7e8a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09081989 0.20815499 0.0504534  0.03316198 0.23499268 0.02139223\n",
      " 0.         0.32439541 0.01236853 0.02426088]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "016ff9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ee4c61a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.35952831e-01, 2.64047169e-01],\n",
       "       [2.94330805e-01, 7.05669195e-01],\n",
       "       [9.87574245e-01, 1.24257552e-02],\n",
       "       [2.78333333e-02, 9.72166667e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [8.69863445e-01, 1.30136555e-01],\n",
       "       [9.16738753e-01, 8.32612472e-02],\n",
       "       [9.51609292e-01, 4.83907083e-02],\n",
       "       [9.69430969e-01, 3.05690310e-02],\n",
       "       [9.76388889e-01, 2.36111111e-02],\n",
       "       [7.82500000e-01, 2.17500000e-01],\n",
       "       [9.13681013e-01, 8.63189873e-02],\n",
       "       [4.38333333e-02, 9.56166667e-01],\n",
       "       [6.98500120e-01, 3.01499880e-01],\n",
       "       [8.63454121e-01, 1.36545879e-01],\n",
       "       [6.73733964e-01, 3.26266036e-01],\n",
       "       [9.59266974e-01, 4.07330263e-02],\n",
       "       [4.99184492e-02, 9.50081551e-01],\n",
       "       [6.72360357e-01, 3.27639643e-01],\n",
       "       [8.64663240e-01, 1.35336760e-01],\n",
       "       [1.17070104e-01, 8.82929896e-01],\n",
       "       [9.68328815e-01, 3.16711855e-02],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [2.25000000e-02, 9.77500000e-01],\n",
       "       [6.17041606e-01, 3.82958394e-01],\n",
       "       [9.80254150e-01, 1.97458499e-02],\n",
       "       [1.00000000e-02, 9.90000000e-01],\n",
       "       [6.05000000e-01, 3.95000000e-01],\n",
       "       [7.14759149e-01, 2.85240851e-01],\n",
       "       [9.21990822e-01, 7.80091776e-02],\n",
       "       [9.71314190e-01, 2.86858100e-02],\n",
       "       [9.72915481e-01, 2.70845188e-02],\n",
       "       [9.80254150e-01, 1.97458499e-02],\n",
       "       [8.24054524e-02, 9.17594548e-01],\n",
       "       [2.28645332e-02, 9.77135467e-01],\n",
       "       [4.96805746e-01, 5.03194254e-01],\n",
       "       [8.67144524e-01, 1.32855476e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [9.06431742e-01, 9.35682580e-02],\n",
       "       [1.02218182e-01, 8.97781818e-01],\n",
       "       [9.58275301e-01, 4.17246989e-02],\n",
       "       [9.64395711e-01, 3.56042888e-02],\n",
       "       [7.63619658e-01, 2.36380342e-01],\n",
       "       [5.58823529e-02, 9.44117647e-01],\n",
       "       [6.21171363e-01, 3.78828637e-01],\n",
       "       [9.56985107e-01, 4.30148925e-02],\n",
       "       [9.69430969e-01, 3.05690310e-02],\n",
       "       [9.74601387e-01, 2.53986135e-02],\n",
       "       [2.86258252e-02, 9.71374175e-01],\n",
       "       [9.39983460e-01, 6.00165398e-02],\n",
       "       [8.71842307e-01, 1.28157693e-01],\n",
       "       [9.68935167e-01, 3.10648335e-02],\n",
       "       [1.07692308e-02, 9.89230769e-01],\n",
       "       [1.00000000e-02, 9.90000000e-01],\n",
       "       [7.85777673e-01, 2.14222327e-01],\n",
       "       [8.35128205e-02, 9.16487179e-01],\n",
       "       [9.70914190e-01, 2.90858100e-02],\n",
       "       [1.83883428e-02, 9.81611657e-01],\n",
       "       [3.72389744e-01, 6.27610256e-01],\n",
       "       [9.61664287e-01, 3.83357126e-02],\n",
       "       [8.96730769e-01, 1.03269231e-01],\n",
       "       [9.58086710e-01, 4.19132900e-02],\n",
       "       [9.64836964e-01, 3.51630355e-02],\n",
       "       [8.49064166e-01, 1.50935834e-01],\n",
       "       [9.17248662e-01, 8.27513382e-02],\n",
       "       [9.69430969e-01, 3.05690310e-02],\n",
       "       [4.87229469e-01, 5.12770531e-01],\n",
       "       [9.48265697e-01, 5.17343026e-02],\n",
       "       [3.50512821e-01, 6.49487179e-01],\n",
       "       [2.28267974e-02, 9.77173203e-01],\n",
       "       [8.98846154e-01, 1.01153846e-01],\n",
       "       [9.68824652e-01, 3.11753478e-02],\n",
       "       [1.28267974e-02, 9.87173203e-01],\n",
       "       [3.10639871e-01, 6.89360129e-01],\n",
       "       [9.69430969e-01, 3.05690310e-02],\n",
       "       [9.05423421e-01, 9.45765794e-02],\n",
       "       [9.69917159e-01, 3.00828410e-02],\n",
       "       [9.55365822e-01, 4.46341776e-02],\n",
       "       [9.74712481e-01, 2.52875193e-02],\n",
       "       [3.83333333e-01, 6.16666667e-01],\n",
       "       [8.98124846e-01, 1.01875154e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [9.56922446e-01, 4.30775535e-02],\n",
       "       [9.09220355e-01, 9.07796454e-02],\n",
       "       [9.34351910e-01, 6.56480903e-02],\n",
       "       [8.78000000e-01, 1.22000000e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [1.71277188e-01, 8.28722812e-01],\n",
       "       [1.25357143e-01, 8.74642857e-01],\n",
       "       [9.55365822e-01, 4.46341776e-02],\n",
       "       [9.04812775e-01, 9.51872246e-02],\n",
       "       [9.69430969e-01, 3.05690310e-02],\n",
       "       [1.73642753e-01, 8.26357247e-01],\n",
       "       [1.00000000e-02, 9.90000000e-01],\n",
       "       [6.71801495e-01, 3.28198505e-01],\n",
       "       [9.58104403e-01, 4.18955971e-02],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [8.69067641e-01, 1.30932359e-01],\n",
       "       [8.79095579e-01, 1.20904421e-01],\n",
       "       [4.33333333e-02, 9.56666667e-01],\n",
       "       [9.65925282e-01, 3.40747175e-02],\n",
       "       [8.44210317e-01, 1.55789683e-01],\n",
       "       [4.28181818e-02, 9.57181818e-01],\n",
       "       [9.63246279e-01, 3.67537212e-02],\n",
       "       [7.33333333e-01, 2.66666667e-01],\n",
       "       [6.25000000e-03, 9.93750000e-01],\n",
       "       [8.97760977e-01, 1.02239023e-01],\n",
       "       [1.53333333e-02, 9.84666667e-01],\n",
       "       [9.68104403e-01, 3.18955971e-02],\n",
       "       [9.79539440e-01, 2.04605599e-02],\n",
       "       [1.77583662e-01, 8.22416338e-01],\n",
       "       [2.76248580e-01, 7.23751420e-01],\n",
       "       [8.79037825e-01, 1.20962175e-01],\n",
       "       [9.75543890e-01, 2.44561103e-02],\n",
       "       [6.10258333e-01, 3.89741667e-01],\n",
       "       [3.70000000e-02, 9.63000000e-01],\n",
       "       [9.79722222e-01, 2.02777778e-02],\n",
       "       [9.65416098e-01, 3.45839015e-02],\n",
       "       [3.75000000e-03, 9.96250000e-01],\n",
       "       [3.04000000e-02, 9.69600000e-01],\n",
       "       [9.34833333e-01, 6.51666667e-02],\n",
       "       [9.78990620e-01, 2.10093796e-02],\n",
       "       [7.74026335e-01, 2.25973665e-01],\n",
       "       [8.44285714e-01, 1.55714286e-01],\n",
       "       [1.62641026e-01, 8.37358974e-01],\n",
       "       [9.86633053e-02, 9.01336695e-01],\n",
       "       [2.78683650e-02, 9.72131635e-01],\n",
       "       [8.28710317e-01, 1.71289683e-01],\n",
       "       [4.90966667e-01, 5.09033333e-01],\n",
       "       [8.81346154e-01, 1.18653846e-01],\n",
       "       [4.99184492e-02, 9.50081551e-01],\n",
       "       [9.29330815e-01, 7.06691854e-02],\n",
       "       [9.74465812e-01, 2.55341880e-02],\n",
       "       [4.52534221e-02, 9.54746578e-01],\n",
       "       [9.10253051e-01, 8.97469490e-02],\n",
       "       [9.70551512e-01, 2.94484884e-02],\n",
       "       [8.89366693e-01, 1.10633307e-01],\n",
       "       [9.59266974e-01, 4.07330263e-02],\n",
       "       [9.07600974e-01, 9.23990261e-02],\n",
       "       [8.06261905e-01, 1.93738095e-01],\n",
       "       [2.06540793e-02, 9.79345921e-01],\n",
       "       [8.57626984e-01, 1.42373016e-01],\n",
       "       [7.13324877e-01, 2.86675123e-01],\n",
       "       [9.79642475e-01, 2.03575246e-02],\n",
       "       [1.75000000e-01, 8.25000000e-01],\n",
       "       [2.04175057e-01, 7.95824943e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [4.77534221e-02, 9.52246578e-01],\n",
       "       [3.00000000e-02, 9.70000000e-01],\n",
       "       [1.00000000e-02, 9.90000000e-01],\n",
       "       [9.58086710e-01, 4.19132900e-02],\n",
       "       [3.68710692e-02, 9.63128931e-01],\n",
       "       [1.45000000e-01, 8.55000000e-01],\n",
       "       [9.56431742e-01, 4.35682580e-02],\n",
       "       [7.09522131e-01, 2.90477869e-01],\n",
       "       [1.56449347e-01, 8.43550653e-01],\n",
       "       [9.59807247e-01, 4.01927529e-02],\n",
       "       [9.58783594e-01, 4.12164061e-02],\n",
       "       [1.71679487e-01, 8.28320513e-01],\n",
       "       [9.33070829e-01, 6.69291711e-02],\n",
       "       [9.17527958e-01, 8.24720418e-02],\n",
       "       [4.23883428e-02, 9.57611657e-01],\n",
       "       [9.22117354e-01, 7.78826464e-02],\n",
       "       [1.67175873e-01, 8.32824127e-01],\n",
       "       [9.46344734e-01, 5.36552659e-02],\n",
       "       [9.73915821e-01, 2.60841794e-02],\n",
       "       [9.27722222e-01, 7.22777778e-02],\n",
       "       [9.65416098e-01, 3.45839015e-02],\n",
       "       [9.07635543e-01, 9.23644569e-02],\n",
       "       [9.20102959e-01, 7.98970410e-02],\n",
       "       [9.38908988e-01, 6.10910124e-02],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [1.71679487e-01, 8.28320513e-01],\n",
       "       [8.82262882e-01, 1.17737118e-01],\n",
       "       [8.07012570e-01, 1.92987430e-01],\n",
       "       [9.11059400e-01, 8.89405996e-02],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [9.22249814e-01, 7.77501864e-02],\n",
       "       [9.55528981e-01, 4.44710192e-02],\n",
       "       [4.36824215e-01, 5.63175785e-01],\n",
       "       [9.44729536e-01, 5.52704637e-02],\n",
       "       [9.68824652e-01, 3.11753478e-02],\n",
       "       [9.79432970e-01, 2.05670304e-02],\n",
       "       [1.00000000e-02, 9.90000000e-01],\n",
       "       [9.79539440e-01, 2.04605599e-02],\n",
       "       [3.49591585e-02, 9.65040842e-01],\n",
       "       [9.30567903e-01, 6.94320968e-02],\n",
       "       [2.03683650e-02, 9.79631635e-01],\n",
       "       [8.41666667e-01, 1.58333333e-01],\n",
       "       [4.74968778e-01, 5.25031222e-01],\n",
       "       [9.12065769e-01, 8.79342312e-02],\n",
       "       [7.69230769e-04, 9.99230769e-01],\n",
       "       [9.17167426e-01, 8.28325736e-02],\n",
       "       [9.59337896e-01, 4.06621039e-02],\n",
       "       [8.00000000e-03, 9.92000000e-01],\n",
       "       [1.64877074e-01, 8.35122926e-01],\n",
       "       [8.87545455e-01, 1.12454545e-01],\n",
       "       [5.07940805e-01, 4.92059195e-01],\n",
       "       [9.01138244e-01, 9.88617564e-02],\n",
       "       [8.73658339e-01, 1.26341661e-01],\n",
       "       [9.79722222e-01, 2.02777778e-02],\n",
       "       [3.80000000e-02, 9.62000000e-01],\n",
       "       [9.00000000e-02, 9.10000000e-01],\n",
       "       [9.07667010e-01, 9.23329903e-02],\n",
       "       [9.41303979e-01, 5.86960212e-02],\n",
       "       [9.60288460e-01, 3.97115404e-02],\n",
       "       [9.10265150e-01, 8.97348499e-02],\n",
       "       [9.22472222e-01, 7.75277778e-02],\n",
       "       [9.59266974e-01, 4.07330263e-02],\n",
       "       [1.44215686e-01, 8.55784314e-01],\n",
       "       [8.25153552e-01, 1.74846448e-01],\n",
       "       [9.68824652e-01, 3.11753478e-02],\n",
       "       [8.44415884e-01, 1.55584116e-01],\n",
       "       [4.25098679e-01, 5.74901321e-01],\n",
       "       [4.61538462e-03, 9.95384615e-01],\n",
       "       [1.83947298e-01, 8.16052702e-01],\n",
       "       [9.71379147e-01, 2.86208527e-02],\n",
       "       [9.78873245e-01, 2.11267554e-02],\n",
       "       [7.56990196e-02, 9.24300980e-01],\n",
       "       [9.71466515e-01, 2.85334847e-02],\n",
       "       [7.50423535e-01, 2.49576465e-01],\n",
       "       [9.59266974e-01, 4.07330263e-02],\n",
       "       [8.75127743e-01, 1.24872257e-01],\n",
       "       [4.61538462e-03, 9.95384615e-01],\n",
       "       [9.79791769e-01, 2.02082308e-02],\n",
       "       [8.77293241e-01, 1.22706759e-01],\n",
       "       [7.49829365e-01, 2.50170635e-01],\n",
       "       [4.59978754e-01, 5.40021246e-01],\n",
       "       [9.66033316e-01, 3.39666842e-02],\n",
       "       [1.11235061e-01, 8.88764939e-01],\n",
       "       [8.64214579e-01, 1.35785421e-01],\n",
       "       [9.34165352e-01, 6.58346478e-02],\n",
       "       [9.79539440e-01, 2.04605599e-02],\n",
       "       [9.06103345e-01, 9.38966552e-02],\n",
       "       [8.73658339e-01, 1.26341661e-01],\n",
       "       [4.31540793e-02, 9.56845921e-01],\n",
       "       [1.81969829e-01, 8.18030171e-01],\n",
       "       [9.64836964e-01, 3.51630355e-02],\n",
       "       [9.34254386e-01, 6.57456140e-02],\n",
       "       [9.66965812e-01, 3.30341880e-02],\n",
       "       [9.17167426e-01, 8.28325736e-02],\n",
       "       [9.22855752e-01, 7.71442475e-02],\n",
       "       [8.28267974e-02, 9.17173203e-01],\n",
       "       [5.85507298e-01, 4.14492702e-01],\n",
       "       [2.00000000e-02, 9.80000000e-01],\n",
       "       [9.70294465e-01, 2.97055354e-02],\n",
       "       [1.07692308e-02, 9.89230769e-01],\n",
       "       [9.18653979e-01, 8.13460207e-02],\n",
       "       [6.84852640e-01, 3.15147360e-01],\n",
       "       [4.13848485e-02, 9.58615152e-01],\n",
       "       [8.26689954e-01, 1.73310046e-01],\n",
       "       [8.24124846e-01, 1.75875154e-01],\n",
       "       [9.77734856e-01, 2.22651437e-02],\n",
       "       [2.66742063e-01, 7.33257937e-01],\n",
       "       [9.25475830e-01, 7.45241700e-02],\n",
       "       [2.01234432e-01, 7.98765568e-01],\n",
       "       [6.37982663e-01, 3.62017337e-01],\n",
       "       [1.00000000e-02, 9.90000000e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [2.05673993e-01, 7.94326007e-01],\n",
       "       [7.99226244e-01, 2.00773756e-01],\n",
       "       [9.58941194e-01, 4.10588058e-02],\n",
       "       [2.86258252e-02, 9.71374175e-01],\n",
       "       [2.00000000e-02, 9.80000000e-01],\n",
       "       [9.20102959e-01, 7.98970410e-02],\n",
       "       [8.92825815e-01, 1.07174185e-01],\n",
       "       [8.42500000e-01, 1.57500000e-01],\n",
       "       [4.38765836e-01, 5.61234164e-01],\n",
       "       [9.68104403e-01, 3.18955971e-02],\n",
       "       [7.82896236e-01, 2.17103764e-01],\n",
       "       [9.36535108e-01, 6.34648923e-02],\n",
       "       [8.09765873e-01, 1.90234127e-01],\n",
       "       [9.61830190e-01, 3.81698101e-02],\n",
       "       [1.07692308e-02, 9.89230769e-01],\n",
       "       [9.76388889e-01, 2.36111111e-02],\n",
       "       [9.43891249e-01, 5.61087507e-02],\n",
       "       [9.60551512e-01, 3.94484884e-02],\n",
       "       [9.59266974e-01, 4.07330263e-02],\n",
       "       [9.59266974e-01, 4.07330263e-02],\n",
       "       [9.60773581e-01, 3.92264188e-02],\n",
       "       [9.60773581e-01, 3.92264188e-02],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [5.50515963e-01, 4.49484037e-01],\n",
       "       [2.86258252e-02, 9.71374175e-01],\n",
       "       [8.72681369e-01, 1.27318631e-01],\n",
       "       [8.95423421e-01, 1.04576579e-01],\n",
       "       [5.19934641e-02, 9.48006536e-01],\n",
       "       [4.51423754e-01, 5.48576246e-01],\n",
       "       [9.40000000e-01, 6.00000000e-02],\n",
       "       [8.97360520e-01, 1.02639480e-01],\n",
       "       [9.29078096e-01, 7.09219045e-02],\n",
       "       [9.56422328e-01, 4.35776718e-02],\n",
       "       [9.59266974e-01, 4.07330263e-02],\n",
       "       [9.61830190e-01, 3.81698101e-02],\n",
       "       [8.47186508e-01, 1.52813492e-01],\n",
       "       [4.84965264e-01, 5.15034736e-01],\n",
       "       [8.74052267e-01, 1.25947733e-01],\n",
       "       [9.58385168e-01, 4.16148323e-02],\n",
       "       [9.75619658e-01, 2.43803419e-02],\n",
       "       [9.39724567e-01, 6.02754329e-02],\n",
       "       [6.56598665e-01, 3.43401335e-01],\n",
       "       [9.58275301e-01, 4.17246989e-02],\n",
       "       [9.67728424e-01, 3.22715760e-02],\n",
       "       [2.86258252e-02, 9.71374175e-01],\n",
       "       [9.77734856e-01, 2.22651437e-02],\n",
       "       [8.91065628e-01, 1.08934372e-01],\n",
       "       [3.07692308e-02, 9.69230769e-01],\n",
       "       [9.68824652e-01, 3.11753478e-02],\n",
       "       [8.86262139e-01, 1.13737861e-01],\n",
       "       [7.73429487e-01, 2.26570513e-01],\n",
       "       [9.59337896e-01, 4.06621039e-02],\n",
       "       [9.80053979e-01, 1.99460212e-02],\n",
       "       [9.89543433e-01, 1.04565668e-02],\n",
       "       [4.11130046e-02, 9.58886995e-01],\n",
       "       [9.35512821e-01, 6.44871795e-02],\n",
       "       [8.66721154e-01, 1.33278846e-01],\n",
       "       [9.68824652e-01, 3.11753478e-02],\n",
       "       [1.25000000e-02, 9.87500000e-01],\n",
       "       [3.74048069e-01, 6.25951931e-01],\n",
       "       [9.89946069e-01, 1.00539308e-02],\n",
       "       [9.34520757e-01, 6.54792430e-02],\n",
       "       [7.82149625e-01, 2.17850375e-01],\n",
       "       [1.25000000e-02, 9.87500000e-01],\n",
       "       [7.23762245e-01, 2.76237755e-01],\n",
       "       [8.92376244e-01, 1.07623756e-01],\n",
       "       [1.71353896e-01, 8.28646104e-01],\n",
       "       [3.67546396e-01, 6.32453604e-01],\n",
       "       [5.39696274e-01, 4.60303726e-01],\n",
       "       [2.58274235e-01, 7.41725765e-01],\n",
       "       [1.33883428e-02, 9.86611657e-01],\n",
       "       [9.58980177e-01, 4.10198225e-02],\n",
       "       [9.26410256e-02, 9.07358974e-01],\n",
       "       [2.86258252e-02, 9.71374175e-01],\n",
       "       [2.59222583e-01, 7.40777417e-01],\n",
       "       [1.94159452e-01, 8.05840548e-01],\n",
       "       [4.99184492e-02, 9.50081551e-01],\n",
       "       [8.56018926e-01, 1.43981074e-01],\n",
       "       [2.64166667e-01, 7.35833333e-01],\n",
       "       [9.68935167e-01, 3.10648335e-02],\n",
       "       [5.25764302e-01, 4.74235698e-01],\n",
       "       [8.95313833e-01, 1.04686167e-01],\n",
       "       [3.90490196e-02, 9.60950980e-01],\n",
       "       [2.16180298e-01, 7.83819702e-01],\n",
       "       [2.72172391e-01, 7.27827609e-01],\n",
       "       [9.24580280e-01, 7.54197196e-02],\n",
       "       [1.57000361e-01, 8.42999639e-01],\n",
       "       [8.95423421e-01, 1.04576579e-01],\n",
       "       [6.94445007e-01, 3.05554993e-01],\n",
       "       [8.47673176e-01, 1.52326824e-01],\n",
       "       [9.13681013e-01, 8.63189873e-02],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [8.81527958e-01, 1.18472042e-01],\n",
       "       [4.51344609e-01, 5.48655391e-01],\n",
       "       [1.02500000e-01, 8.97500000e-01],\n",
       "       [3.29874126e-02, 9.67012587e-01],\n",
       "       [1.00000000e-02, 9.90000000e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [8.71142621e-01, 1.28857379e-01],\n",
       "       [8.66721154e-01, 1.33278846e-01],\n",
       "       [1.66666667e-01, 8.33333333e-01],\n",
       "       [8.95746195e-01, 1.04253805e-01],\n",
       "       [3.16500000e-01, 6.83500000e-01],\n",
       "       [4.77534221e-02, 9.52246578e-01],\n",
       "       [7.62500000e-01, 2.37500000e-01],\n",
       "       [9.82402997e-01, 1.75970030e-02],\n",
       "       [6.58111472e-01, 3.41888528e-01],\n",
       "       [6.72360357e-01, 3.27639643e-01],\n",
       "       [9.32089959e-01, 6.79100409e-02],\n",
       "       [8.92296467e-01, 1.07703533e-01],\n",
       "       [7.40899570e-01, 2.59100430e-01],\n",
       "       [9.59337896e-01, 4.06621039e-02],\n",
       "       [8.66398754e-01, 1.33601246e-01],\n",
       "       [1.54718434e-01, 8.45281566e-01],\n",
       "       [9.24205569e-01, 7.57944309e-02],\n",
       "       [1.36132576e-01, 8.63867424e-01],\n",
       "       [7.35733114e-01, 2.64266886e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [5.92163305e-01, 4.07836695e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [3.65285714e-01, 6.34714286e-01],\n",
       "       [7.53333333e-02, 9.24666667e-01],\n",
       "       [5.86666667e-02, 9.41333333e-01],\n",
       "       [2.28267974e-02, 9.77173203e-01],\n",
       "       [8.71276873e-01, 1.28723127e-01],\n",
       "       [7.55341991e-01, 2.44658009e-01],\n",
       "       [2.72494515e-02, 9.72750548e-01],\n",
       "       [8.44415884e-01, 1.55584116e-01],\n",
       "       [2.13887044e-01, 7.86112956e-01],\n",
       "       [7.46277778e-01, 2.53722222e-01],\n",
       "       [9.63171426e-01, 3.68285738e-02],\n",
       "       [8.93666245e-01, 1.06333755e-01],\n",
       "       [6.01246054e-01, 3.98753946e-01],\n",
       "       [8.54579391e-01, 1.45420609e-01],\n",
       "       [6.21388343e-01, 3.78611657e-01],\n",
       "       [2.84470779e-01, 7.15529221e-01],\n",
       "       [7.51873540e-01, 2.48126460e-01],\n",
       "       [9.04000000e-02, 9.09600000e-01],\n",
       "       [9.71466515e-01, 2.85334847e-02],\n",
       "       [9.02376244e-01, 9.76237559e-02],\n",
       "       [6.53948496e-01, 3.46051504e-01],\n",
       "       [9.39549884e-01, 6.04501155e-02],\n",
       "       [6.42156863e-02, 9.35784314e-01],\n",
       "       [9.39119824e-01, 6.08801762e-02],\n",
       "       [8.33304113e-01, 1.66695887e-01],\n",
       "       [9.26580940e-01, 7.34190604e-02],\n",
       "       [6.23156228e-01, 3.76843772e-01],\n",
       "       [9.36388834e-01, 6.36111664e-02],\n",
       "       [8.40043835e-01, 1.59956165e-01],\n",
       "       [9.66754386e-01, 3.32456140e-02],\n",
       "       [5.85640346e-01, 4.14359654e-01],\n",
       "       [9.13681013e-01, 8.63189873e-02],\n",
       "       [9.66401786e-01, 3.35982137e-02],\n",
       "       [9.80847551e-01, 1.91524486e-02],\n",
       "       [9.02662338e-01, 9.73376623e-02],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [3.83883428e-02, 9.61611657e-01],\n",
       "       [6.25000000e-03, 9.93750000e-01],\n",
       "       [7.12053710e-01, 2.87946290e-01],\n",
       "       [2.50000000e-03, 9.97500000e-01],\n",
       "       [7.56336670e-01, 2.43663330e-01],\n",
       "       [3.55361110e-01, 6.44638890e-01],\n",
       "       [9.43077754e-01, 5.69222456e-02],\n",
       "       [9.58086710e-01, 4.19132900e-02],\n",
       "       [3.70000000e-02, 9.63000000e-01],\n",
       "       [9.03235208e-01, 9.67647916e-02],\n",
       "       [1.77534221e-02, 9.82246578e-01],\n",
       "       [8.12472876e-01, 1.87527124e-01],\n",
       "       [2.32181818e-02, 9.76781818e-01],\n",
       "       [9.68809844e-01, 3.11901557e-02],\n",
       "       [7.02179487e-01, 2.97820513e-01],\n",
       "       [9.68824652e-01, 3.11753478e-02],\n",
       "       [9.06168003e-01, 9.38319968e-02],\n",
       "       [9.85043890e-01, 1.49561103e-02],\n",
       "       [9.72915481e-01, 2.70845188e-02],\n",
       "       [1.70000000e-01, 8.30000000e-01],\n",
       "       [6.29022108e-01, 3.70977892e-01],\n",
       "       [7.26977273e-01, 2.73022727e-01],\n",
       "       [9.63246279e-01, 3.67537212e-02],\n",
       "       [3.33333333e-02, 9.66666667e-01],\n",
       "       [9.72566570e-01, 2.74334299e-02],\n",
       "       [9.68824652e-01, 3.11753478e-02],\n",
       "       [8.72756410e-01, 1.27243590e-01],\n",
       "       [9.13353900e-01, 8.66461005e-02],\n",
       "       [8.05976244e-01, 1.94023756e-01],\n",
       "       [9.68104403e-01, 3.18955971e-02],\n",
       "       [2.61706573e-01, 7.38293427e-01],\n",
       "       [9.64907814e-01, 3.50921856e-02],\n",
       "       [9.79722222e-01, 2.02777778e-02],\n",
       "       [3.85964656e-01, 6.14035344e-01],\n",
       "       [9.48629382e-01, 5.13706175e-02],\n",
       "       [1.37916306e-01, 8.62083694e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [9.18653979e-01, 8.13460207e-02],\n",
       "       [9.17367354e-01, 8.26326464e-02],\n",
       "       [5.16666667e-02, 9.48333333e-01],\n",
       "       [3.47303706e-01, 6.52696294e-01],\n",
       "       [9.57735043e-01, 4.22649573e-02],\n",
       "       [8.90351590e-01, 1.09648410e-01],\n",
       "       [9.29460331e-01, 7.05396691e-02],\n",
       "       [9.59337896e-01, 4.06621039e-02],\n",
       "       [9.32288755e-01, 6.77112449e-02],\n",
       "       [9.75798359e-01, 2.42016407e-02],\n",
       "       [4.23883428e-02, 9.57611657e-01],\n",
       "       [9.33738095e-01, 6.62619048e-02],\n",
       "       [9.21333333e-01, 7.86666667e-02],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [3.69543651e-01, 6.30456349e-01],\n",
       "       [9.19556991e-01, 8.04430088e-02],\n",
       "       [2.50000000e-01, 7.50000000e-01],\n",
       "       [9.46977897e-01, 5.30221030e-02],\n",
       "       [1.83883428e-02, 9.81611657e-01],\n",
       "       [7.04607471e-01, 2.95392529e-01],\n",
       "       [9.29724567e-01, 7.02754329e-02],\n",
       "       [9.51176017e-01, 4.88239828e-02],\n",
       "       [9.76437741e-01, 2.35622590e-02],\n",
       "       [8.44415884e-01, 1.55584116e-01],\n",
       "       [7.75342212e-03, 9.92246578e-01],\n",
       "       [7.73010753e-01, 2.26989247e-01],\n",
       "       [8.76851951e-01, 1.23148049e-01],\n",
       "       [9.65416098e-01, 3.45839015e-02],\n",
       "       [3.64757937e-01, 6.35242063e-01],\n",
       "       [1.00000000e-02, 9.90000000e-01],\n",
       "       [1.29262266e-01, 8.70737734e-01],\n",
       "       [2.00000000e-02, 9.80000000e-01],\n",
       "       [9.56922446e-01, 4.30775535e-02],\n",
       "       [4.26900794e-01, 5.73099206e-01],\n",
       "       [6.86425534e-01, 3.13574466e-01],\n",
       "       [8.36452020e-02, 9.16354798e-01],\n",
       "       [9.59266974e-01, 4.07330263e-02],\n",
       "       [3.80307012e-01, 6.19692988e-01],\n",
       "       [4.70000000e-02, 9.53000000e-01],\n",
       "       [9.24466861e-01, 7.55331390e-02],\n",
       "       [2.00000000e-02, 9.80000000e-01],\n",
       "       [9.68660298e-01, 3.13397019e-02],\n",
       "       [8.16019269e-01, 1.83980731e-01],\n",
       "       [8.56562912e-01, 1.43437088e-01],\n",
       "       [9.34520757e-01, 6.54792430e-02],\n",
       "       [7.22917585e-01, 2.77082415e-01]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = rf.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c8a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8f57415",
   "metadata": {},
   "source": [
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f665e587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.97\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77afff7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  307    0\n",
       "1   15  176"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = pd.DataFrame(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "conf_matrix\n",
    "# confusion matrix - actual on left, predicted on top\n",
    "\n",
    "# 0 = 'perished', 1= 'survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c6bd626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       307\n",
      "           1       1.00      0.92      0.96       191\n",
      "\n",
      "    accuracy                           0.97       498\n",
      "   macro avg       0.98      0.96      0.97       498\n",
      "weighted avg       0.97      0.97      0.97       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be0498c",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a55489e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9678714859437751\n",
      "True Positive Rate: 1.0\n",
      "False Positive Rate: 0.08376963350785341\n",
      "True Negative Rate: 0.9162303664921466\n",
      "False Negative Rate: 0.0\n",
      "Precision: 0.9504643962848297\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9746031746031747\n",
      "Support (0): 307\n",
      "Support (1): 191\n"
     ]
    }
   ],
   "source": [
    "TP = 307\n",
    "FP = 16\n",
    "FN = 0\n",
    "TN = 175\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c0f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc8f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "446efb85",
   "metadata": {},
   "source": [
    "### 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "47954cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 20 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       307\n",
      "           1       1.00      0.99      0.99       191\n",
      "\n",
      "    accuracy                           1.00       498\n",
      "   macro avg       1.00      0.99      1.00       498\n",
      "weighted avg       1.00      1.00      1.00       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94       307\n",
      "           1       0.96      0.84      0.89       191\n",
      "\n",
      "    accuracy                           0.92       498\n",
      "   macro avg       0.93      0.91      0.92       498\n",
      "weighted avg       0.93      0.92      0.92       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       307\n",
      "           1       0.94      0.80      0.86       191\n",
      "\n",
      "    accuracy                           0.90       498\n",
      "   macro avg       0.91      0.88      0.89       498\n",
      "weighted avg       0.90      0.90      0.90       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       307\n",
      "           1       0.94      0.76      0.84       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.90      0.86      0.88       498\n",
      "weighted avg       0.90      0.89      0.89       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       307\n",
      "           1       0.93      0.74      0.83       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.89      0.85      0.87       498\n",
      "weighted avg       0.88      0.88      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       307\n",
      "           1       0.90      0.74      0.81       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.88      0.85      0.86       498\n",
      "weighted avg       0.87      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       307\n",
      "           1       0.90      0.71      0.79       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.83      0.84       498\n",
      "weighted avg       0.86      0.86      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89       307\n",
      "           1       0.93      0.68      0.79       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.88      0.82      0.84       498\n",
      "weighted avg       0.87      0.86      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       307\n",
      "           1       0.90      0.72      0.80       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.83      0.85       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.80      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       307\n",
      "           1       0.92      0.64      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.87      0.80      0.82       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.67      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       307\n",
      "           1       0.89      0.69      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.89      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.80      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.88      0.64      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.86      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       307\n",
      "           1       0.90      0.62      0.73       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.80       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       307\n",
      "           1       0.81      0.69      0.74       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.82      0.79      0.80       498\n",
      "weighted avg       0.82      0.82      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 20 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.87      0.65      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       307\n",
      "           1       1.00      0.99      0.99       191\n",
      "\n",
      "    accuracy                           1.00       498\n",
      "   macro avg       1.00      0.99      1.00       498\n",
      "weighted avg       1.00      1.00      1.00       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       307\n",
      "           1       0.96      0.83      0.89       191\n",
      "\n",
      "    accuracy                           0.92       498\n",
      "   macro avg       0.93      0.90      0.91       498\n",
      "weighted avg       0.92      0.92      0.92       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 19 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       307\n",
      "           1       0.94      0.81      0.87       191\n",
      "\n",
      "    accuracy                           0.91       498\n",
      "   macro avg       0.91      0.89      0.90       498\n",
      "weighted avg       0.91      0.91      0.90       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       307\n",
      "           1       0.93      0.78      0.85       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.90      0.87      0.88       498\n",
      "weighted avg       0.89      0.89      0.89       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       307\n",
      "           1       0.92      0.75      0.83       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.89      0.86      0.87       498\n",
      "weighted avg       0.88      0.88      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       307\n",
      "           1       0.92      0.74      0.82       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.89      0.85      0.86       498\n",
      "weighted avg       0.88      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90       307\n",
      "           1       0.91      0.72      0.80       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.88      0.84      0.85       498\n",
      "weighted avg       0.87      0.87      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       307\n",
      "           1       0.91      0.70      0.79       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.83      0.84       498\n",
      "weighted avg       0.86      0.86      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       307\n",
      "           1       0.90      0.70      0.79       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.83      0.84       498\n",
      "weighted avg       0.86      0.86      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       307\n",
      "           1       0.90      0.69      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.82      0.83       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       307\n",
      "           1       0.91      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.82      0.83       498\n",
      "weighted avg       0.86      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89       307\n",
      "           1       0.91      0.67      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.81      0.83       498\n",
      "weighted avg       0.86      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.86      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.84      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.87      0.65      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       307\n",
      "           1       0.86      0.65      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.79      0.80       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.86      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.82       498\n",
      "weighted avg       0.84      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.90      0.63      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87       307\n",
      "           1       0.84      0.69      0.76       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.83      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       307\n",
      "           1       0.89      0.61      0.72       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.84      0.78      0.80       498\n",
      "weighted avg       0.83      0.82      0.81       498\n",
      "\n",
      "\n",
      "Forest with max depth of 19 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.89      0.64      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       307\n",
      "           1       1.00      0.99      0.99       191\n",
      "\n",
      "    accuracy                           1.00       498\n",
      "   macro avg       1.00      0.99      1.00       498\n",
      "weighted avg       1.00      1.00      1.00       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       307\n",
      "           1       0.95      0.85      0.90       191\n",
      "\n",
      "    accuracy                           0.93       498\n",
      "   macro avg       0.93      0.91      0.92       498\n",
      "weighted avg       0.93      0.93      0.92       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       307\n",
      "           1       0.94      0.81      0.87       191\n",
      "\n",
      "    accuracy                           0.91       498\n",
      "   macro avg       0.91      0.89      0.90       498\n",
      "weighted avg       0.91      0.91      0.90       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92       307\n",
      "           1       0.93      0.77      0.85       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.90      0.87      0.88       498\n",
      "weighted avg       0.90      0.89      0.89       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 18 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       307\n",
      "           1       0.93      0.77      0.84       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.90      0.87      0.88       498\n",
      "weighted avg       0.89      0.89      0.89       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.91       307\n",
      "           1       0.93      0.73      0.82       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.89      0.85      0.86       498\n",
      "weighted avg       0.88      0.88      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.90       307\n",
      "           1       0.89      0.73      0.80       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.84      0.85       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       307\n",
      "           1       0.91      0.70      0.79       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.83      0.84       498\n",
      "weighted avg       0.86      0.86      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       307\n",
      "           1       0.92      0.69      0.78       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.82      0.84       498\n",
      "weighted avg       0.86      0.86      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       307\n",
      "           1       0.87      0.69      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.83       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88       307\n",
      "           1       0.89      0.69      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.87      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88       307\n",
      "           1       0.89      0.65      0.75       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88       307\n",
      "           1       0.89      0.65      0.75       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       307\n",
      "           1       0.88      0.63      0.73       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.79      0.80       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.87      0.67      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.80      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.85      0.68      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 18 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.86      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.84      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       307\n",
      "           1       1.00      0.99      0.99       191\n",
      "\n",
      "    accuracy                           1.00       498\n",
      "   macro avg       1.00      0.99      1.00       498\n",
      "weighted avg       1.00      1.00      1.00       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       307\n",
      "           1       0.95      0.85      0.90       191\n",
      "\n",
      "    accuracy                           0.93       498\n",
      "   macro avg       0.93      0.91      0.92       498\n",
      "weighted avg       0.93      0.93      0.93       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       307\n",
      "           1       0.94      0.80      0.86       191\n",
      "\n",
      "    accuracy                           0.90       498\n",
      "   macro avg       0.91      0.88      0.89       498\n",
      "weighted avg       0.90      0.90      0.90       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       307\n",
      "           1       0.93      0.76      0.84       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.90      0.86      0.87       498\n",
      "weighted avg       0.89      0.89      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       307\n",
      "           1       0.93      0.74      0.83       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.90      0.86      0.87       498\n",
      "weighted avg       0.89      0.88      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       307\n",
      "           1       0.92      0.73      0.82       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.89      0.85      0.86       498\n",
      "weighted avg       0.88      0.87      0.87       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 17 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       307\n",
      "           1       0.93      0.72      0.81       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.89      0.84      0.86       498\n",
      "weighted avg       0.88      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       307\n",
      "           1       0.90      0.70      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.82      0.84       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88       307\n",
      "           1       0.89      0.69      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       307\n",
      "           1       0.92      0.71      0.80       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.88      0.83      0.85       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88       307\n",
      "           1       0.91      0.66      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.81      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.90      0.67      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.81      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.89      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.89      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.88       307\n",
      "           1       0.87      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.84      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.87      0.65      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       307\n",
      "           1       0.90      0.63      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.87       307\n",
      "           1       0.85      0.69      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.84      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88       307\n",
      "           1       0.90      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 17 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87       307\n",
      "           1       0.84      0.68      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.83      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       307\n",
      "           1       1.00      0.99      0.99       191\n",
      "\n",
      "    accuracy                           1.00       498\n",
      "   macro avg       1.00      0.99      1.00       498\n",
      "weighted avg       1.00      1.00      1.00       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94       307\n",
      "           1       0.95      0.83      0.89       191\n",
      "\n",
      "    accuracy                           0.92       498\n",
      "   macro avg       0.93      0.90      0.91       498\n",
      "weighted avg       0.92      0.92      0.92       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.93       307\n",
      "           1       0.95      0.79      0.86       191\n",
      "\n",
      "    accuracy                           0.90       498\n",
      "   macro avg       0.92      0.88      0.89       498\n",
      "weighted avg       0.91      0.90      0.90       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       307\n",
      "           1       0.93      0.75      0.83       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.90      0.86      0.87       498\n",
      "weighted avg       0.89      0.88      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       307\n",
      "           1       0.93      0.76      0.84       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.90      0.86      0.88       498\n",
      "weighted avg       0.89      0.89      0.89       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       307\n",
      "           1       0.91      0.74      0.82       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.88      0.85      0.86       498\n",
      "weighted avg       0.88      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       307\n",
      "           1       0.92      0.74      0.82       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.89      0.85      0.86       498\n",
      "weighted avg       0.88      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       307\n",
      "           1       0.91      0.71      0.80       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.88      0.83      0.85       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 16 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90       307\n",
      "           1       0.90      0.73      0.81       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.87      0.84      0.85       498\n",
      "weighted avg       0.87      0.87      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       307\n",
      "           1       0.88      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.81      0.83       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89       307\n",
      "           1       0.92      0.67      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.82      0.83       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.89      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.88      0.64      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.80      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.80      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       307\n",
      "           1       0.90      0.64      0.75       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.80      0.81       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87       307\n",
      "           1       0.87      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.85      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.87      0.65      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 16 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.88       307\n",
      "           1       0.87      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       307\n",
      "           1       1.00      0.99      0.99       191\n",
      "\n",
      "    accuracy                           1.00       498\n",
      "   macro avg       1.00      0.99      1.00       498\n",
      "weighted avg       1.00      1.00      1.00       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94       307\n",
      "           1       0.96      0.84      0.89       191\n",
      "\n",
      "    accuracy                           0.92       498\n",
      "   macro avg       0.93      0.91      0.92       498\n",
      "weighted avg       0.93      0.92      0.92       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       307\n",
      "           1       0.93      0.80      0.86       191\n",
      "\n",
      "    accuracy                           0.90       498\n",
      "   macro avg       0.91      0.88      0.89       498\n",
      "weighted avg       0.90      0.90      0.90       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       307\n",
      "           1       0.94      0.76      0.84       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.90      0.87      0.88       498\n",
      "weighted avg       0.89      0.89      0.89       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       307\n",
      "           1       0.93      0.75      0.83       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.89      0.86      0.87       498\n",
      "weighted avg       0.89      0.88      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       307\n",
      "           1       0.89      0.74      0.81       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.84      0.85       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90       307\n",
      "           1       0.91      0.74      0.82       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.88      0.85      0.86       498\n",
      "weighted avg       0.88      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90       307\n",
      "           1       0.93      0.71      0.81       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.89      0.84      0.85       498\n",
      "weighted avg       0.88      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       307\n",
      "           1       0.91      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.82      0.83       498\n",
      "weighted avg       0.86      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       307\n",
      "           1       0.90      0.69      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.83       498\n",
      "weighted avg       0.86      0.85      0.84       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 15 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.90      0.63      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       307\n",
      "           1       0.90      0.69      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.83       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       307\n",
      "           1       0.90      0.64      0.75       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.80      0.81       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       307\n",
      "           1       0.86      0.65      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.83      0.79      0.80       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.87      0.65      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       307\n",
      "           1       0.84      0.69      0.76       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.83      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.86      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       307\n",
      "           1       0.82      0.66      0.73       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.82      0.79      0.80       498\n",
      "weighted avg       0.82      0.82      0.81       498\n",
      "\n",
      "\n",
      "Forest with max depth of 15 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.88      0.65      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       307\n",
      "           1       1.00      0.99      0.99       191\n",
      "\n",
      "    accuracy                           1.00       498\n",
      "   macro avg       1.00      0.99      1.00       498\n",
      "weighted avg       1.00      1.00      1.00       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       307\n",
      "           1       0.96      0.83      0.89       191\n",
      "\n",
      "    accuracy                           0.92       498\n",
      "   macro avg       0.93      0.90      0.91       498\n",
      "weighted avg       0.92      0.92      0.92       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       307\n",
      "           1       0.94      0.80      0.87       191\n",
      "\n",
      "    accuracy                           0.91       498\n",
      "   macro avg       0.92      0.89      0.90       498\n",
      "weighted avg       0.91      0.91      0.90       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       307\n",
      "           1       0.92      0.77      0.84       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.89      0.86      0.87       498\n",
      "weighted avg       0.89      0.89      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       307\n",
      "           1       0.94      0.75      0.83       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.90      0.86      0.87       498\n",
      "weighted avg       0.89      0.89      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       307\n",
      "           1       0.92      0.73      0.82       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.89      0.85      0.86       498\n",
      "weighted avg       0.88      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       307\n",
      "           1       0.92      0.72      0.81       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.88      0.84      0.85       498\n",
      "weighted avg       0.87      0.87      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88       307\n",
      "           1       0.89      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.81      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89       307\n",
      "           1       0.91      0.70      0.79       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.83      0.84       498\n",
      "weighted avg       0.86      0.86      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       307\n",
      "           1       0.90      0.71      0.79       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.83      0.84       498\n",
      "weighted avg       0.86      0.86      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88       307\n",
      "           1       0.89      0.65      0.75       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.80      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 14 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       307\n",
      "           1       0.87      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88       307\n",
      "           1       0.91      0.65      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87       307\n",
      "           1       0.88      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       307\n",
      "           1       0.83      0.70      0.76       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.83      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.88      0.64      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.88      0.63      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.79      0.80       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       307\n",
      "           1       0.82      0.70      0.75       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.82      0.80      0.81       498\n",
      "weighted avg       0.82      0.82      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 14 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86       307\n",
      "           1       0.87      0.61      0.72       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.83      0.78      0.79       498\n",
      "weighted avg       0.83      0.82      0.81       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       307\n",
      "           1       1.00      0.97      0.99       191\n",
      "\n",
      "    accuracy                           0.99       498\n",
      "   macro avg       0.99      0.99      0.99       498\n",
      "weighted avg       0.99      0.99      0.99       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94       307\n",
      "           1       0.96      0.84      0.89       191\n",
      "\n",
      "    accuracy                           0.92       498\n",
      "   macro avg       0.93      0.91      0.92       498\n",
      "weighted avg       0.93      0.92      0.92       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       307\n",
      "           1       0.93      0.80      0.86       191\n",
      "\n",
      "    accuracy                           0.90       498\n",
      "   macro avg       0.91      0.88      0.89       498\n",
      "weighted avg       0.90      0.90      0.90       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       307\n",
      "           1       0.93      0.78      0.85       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.90      0.87      0.88       498\n",
      "weighted avg       0.89      0.89      0.89       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       307\n",
      "           1       0.90      0.75      0.82       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.88      0.85      0.86       498\n",
      "weighted avg       0.87      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       307\n",
      "           1       0.92      0.72      0.81       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.88      0.84      0.86       498\n",
      "weighted avg       0.88      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       307\n",
      "           1       0.93      0.72      0.81       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.89      0.84      0.85       498\n",
      "weighted avg       0.88      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.89       307\n",
      "           1       0.90      0.72      0.80       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.84      0.85       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       307\n",
      "           1       0.92      0.70      0.80       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.88      0.83      0.85       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88       307\n",
      "           1       0.90      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.89      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       307\n",
      "           1       0.91      0.65      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.80      0.82       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       307\n",
      "           1       0.87      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.87       307\n",
      "           1       0.85      0.69      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.84      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 13 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.80      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.88       307\n",
      "           1       0.91      0.62      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.86      0.79      0.81       498\n",
      "weighted avg       0.85      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       307\n",
      "           1       0.89      0.62      0.73       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.80       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       307\n",
      "           1       0.88      0.62      0.73       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.84      0.78      0.80       498\n",
      "weighted avg       0.83      0.82      0.81       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.86      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 13 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87       307\n",
      "           1       0.88      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       307\n",
      "           1       1.00      0.96      0.98       191\n",
      "\n",
      "    accuracy                           0.98       498\n",
      "   macro avg       0.99      0.98      0.98       498\n",
      "weighted avg       0.98      0.98      0.98       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94       307\n",
      "           1       0.96      0.84      0.89       191\n",
      "\n",
      "    accuracy                           0.92       498\n",
      "   macro avg       0.93      0.91      0.92       498\n",
      "weighted avg       0.93      0.92      0.92       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       307\n",
      "           1       0.93      0.81      0.87       191\n",
      "\n",
      "    accuracy                           0.90       498\n",
      "   macro avg       0.91      0.89      0.90       498\n",
      "weighted avg       0.91      0.90      0.90       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       307\n",
      "           1       0.92      0.76      0.83       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.89      0.86      0.87       498\n",
      "weighted avg       0.89      0.88      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.91       307\n",
      "           1       0.91      0.76      0.83       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.89      0.86      0.87       498\n",
      "weighted avg       0.88      0.88      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90       307\n",
      "           1       0.90      0.73      0.81       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.88      0.84      0.85       498\n",
      "weighted avg       0.87      0.87      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       307\n",
      "           1       0.91      0.71      0.79       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.83      0.84       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.89       307\n",
      "           1       0.90      0.72      0.80       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.84      0.85       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89       307\n",
      "           1       0.93      0.66      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.81      0.83       498\n",
      "weighted avg       0.86      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.90      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.81      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       307\n",
      "           1       0.87      0.69      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.88      0.64      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       307\n",
      "           1       0.85      0.69      0.76       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.81      0.82       498\n",
      "weighted avg       0.83      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.87      0.67      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.80      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.89      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.80      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       307\n",
      "           1       0.88      0.63      0.73       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.79      0.80       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 12 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87       307\n",
      "           1       0.88      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.88       307\n",
      "           1       0.92      0.62      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.86      0.79      0.81       498\n",
      "weighted avg       0.85      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 12 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.89      0.63      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       307\n",
      "           1       0.99      0.93      0.96       191\n",
      "\n",
      "    accuracy                           0.97       498\n",
      "   macro avg       0.98      0.96      0.97       498\n",
      "weighted avg       0.97      0.97      0.97       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       307\n",
      "           1       0.95      0.85      0.90       191\n",
      "\n",
      "    accuracy                           0.93       498\n",
      "   macro avg       0.93      0.91      0.92       498\n",
      "weighted avg       0.93      0.93      0.92       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       307\n",
      "           1       0.93      0.80      0.86       191\n",
      "\n",
      "    accuracy                           0.90       498\n",
      "   macro avg       0.91      0.88      0.89       498\n",
      "weighted avg       0.90      0.90      0.90       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       307\n",
      "           1       0.93      0.75      0.83       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.90      0.86      0.87       498\n",
      "weighted avg       0.89      0.88      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       307\n",
      "           1       0.93      0.76      0.84       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.90      0.86      0.87       498\n",
      "weighted avg       0.89      0.89      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       307\n",
      "           1       0.92      0.74      0.82       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.89      0.85      0.86       498\n",
      "weighted avg       0.88      0.88      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       307\n",
      "           1       0.89      0.73      0.80       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.84      0.85       498\n",
      "weighted avg       0.86      0.86      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       307\n",
      "           1       0.92      0.71      0.80       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.88      0.83      0.85       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       307\n",
      "           1       0.91      0.69      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.82      0.84       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89       307\n",
      "           1       0.93      0.66      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.82      0.83       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.89      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.90      0.65      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.80      0.82       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       307\n",
      "           1       0.88      0.70      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.86      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.90      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.81      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       307\n",
      "           1       0.90      0.62      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.87      0.64      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.79      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       307\n",
      "           1       0.87      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 11 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.88      0.65      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 11 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88       307\n",
      "           1       0.89      0.65      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       307\n",
      "           1       1.00      0.92      0.96       191\n",
      "\n",
      "    accuracy                           0.97       498\n",
      "   macro avg       0.98      0.96      0.97       498\n",
      "weighted avg       0.97      0.97      0.97       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       307\n",
      "           1       0.95      0.84      0.89       191\n",
      "\n",
      "    accuracy                           0.92       498\n",
      "   macro avg       0.93      0.91      0.92       498\n",
      "weighted avg       0.92      0.92      0.92       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.93       307\n",
      "           1       0.94      0.80      0.86       191\n",
      "\n",
      "    accuracy                           0.90       498\n",
      "   macro avg       0.91      0.88      0.89       498\n",
      "weighted avg       0.91      0.90      0.90       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       307\n",
      "           1       0.92      0.79      0.85       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.90      0.87      0.88       498\n",
      "weighted avg       0.90      0.89      0.89       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       307\n",
      "           1       0.92      0.77      0.84       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.89      0.86      0.87       498\n",
      "weighted avg       0.89      0.89      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       307\n",
      "           1       0.91      0.75      0.82       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.89      0.85      0.86       498\n",
      "weighted avg       0.88      0.88      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90       307\n",
      "           1       0.90      0.74      0.81       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.88      0.84      0.86       498\n",
      "weighted avg       0.87      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       307\n",
      "           1       0.91      0.70      0.79       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.83      0.84       498\n",
      "weighted avg       0.86      0.86      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89       307\n",
      "           1       0.91      0.70      0.79       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.83      0.84       498\n",
      "weighted avg       0.87      0.86      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       307\n",
      "           1       0.90      0.64      0.75       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.80      0.82       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.90      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.81      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.90      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.88       307\n",
      "           1       0.87      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.86      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.84      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       307\n",
      "           1       0.81      0.69      0.75       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.82      0.80      0.80       498\n",
      "weighted avg       0.82      0.82      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       307\n",
      "           1       0.84      0.69      0.76       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.83      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.89      0.64      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       307\n",
      "           1       0.86      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 10 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.86      0.67      0.76       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.83       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 9 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       307\n",
      "           1       0.99      0.89      0.94       191\n",
      "\n",
      "    accuracy                           0.96       498\n",
      "   macro avg       0.96      0.94      0.95       498\n",
      "weighted avg       0.96      0.96      0.96       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       307\n",
      "           1       0.96      0.82      0.88       191\n",
      "\n",
      "    accuracy                           0.92       498\n",
      "   macro avg       0.93      0.90      0.91       498\n",
      "weighted avg       0.92      0.92      0.92       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       307\n",
      "           1       0.93      0.81      0.86       191\n",
      "\n",
      "    accuracy                           0.90       498\n",
      "   macro avg       0.91      0.88      0.89       498\n",
      "weighted avg       0.90      0.90      0.90       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       307\n",
      "           1       0.93      0.77      0.84       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.90      0.87      0.88       498\n",
      "weighted avg       0.89      0.89      0.89       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       307\n",
      "           1       0.93      0.74      0.83       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.90      0.86      0.87       498\n",
      "weighted avg       0.89      0.88      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       307\n",
      "           1       0.92      0.75      0.83       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.89      0.85      0.87       498\n",
      "weighted avg       0.88      0.88      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90       307\n",
      "           1       0.91      0.74      0.82       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.88      0.85      0.86       498\n",
      "weighted avg       0.88      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       307\n",
      "           1       0.91      0.72      0.81       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.88      0.84      0.85       498\n",
      "weighted avg       0.87      0.87      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       307\n",
      "           1       0.89      0.70      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.83       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       307\n",
      "           1       0.90      0.68      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.82      0.83       498\n",
      "weighted avg       0.86      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89       307\n",
      "           1       0.92      0.67      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.82      0.83       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88       307\n",
      "           1       0.92      0.65      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.87      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.88      0.65      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       307\n",
      "           1       0.91      0.65      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.80      0.82       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.87      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.85      0.68      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.90      0.63      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       307\n",
      "           1       0.90      0.63      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.88      0.64      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 9 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.88      0.63      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.79      0.80       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95       307\n",
      "           1       0.98      0.84      0.91       191\n",
      "\n",
      "    accuracy                           0.93       498\n",
      "   macro avg       0.95      0.92      0.93       498\n",
      "weighted avg       0.94      0.93      0.93       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       307\n",
      "           1       0.95      0.81      0.87       191\n",
      "\n",
      "    accuracy                           0.91       498\n",
      "   macro avg       0.92      0.89      0.90       498\n",
      "weighted avg       0.91      0.91      0.91       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 8 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92       307\n",
      "           1       0.93      0.81      0.87       191\n",
      "\n",
      "    accuracy                           0.90       498\n",
      "   macro avg       0.91      0.89      0.90       498\n",
      "weighted avg       0.91      0.90      0.90       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       307\n",
      "           1       0.94      0.77      0.84       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.90      0.87      0.88       498\n",
      "weighted avg       0.90      0.89      0.89       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       307\n",
      "           1       0.92      0.76      0.83       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.89      0.86      0.87       498\n",
      "weighted avg       0.89      0.88      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.91       307\n",
      "           1       0.93      0.73      0.82       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.89      0.85      0.86       498\n",
      "weighted avg       0.88      0.88      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       307\n",
      "           1       0.92      0.72      0.81       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.88      0.84      0.86       498\n",
      "weighted avg       0.88      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89       307\n",
      "           1       0.91      0.71      0.80       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.88      0.83      0.85       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       307\n",
      "           1       0.90      0.70      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.82      0.84       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88       307\n",
      "           1       0.87      0.70      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.85      0.82      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88       307\n",
      "           1       0.90      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.90      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.81      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       307\n",
      "           1       0.88      0.69      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.83       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.89      0.64      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.90      0.63      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.88      0.64      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.88      0.64      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.86      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.88      0.64      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 8 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.87      0.65      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       307\n",
      "           1       0.96      0.83      0.89       191\n",
      "\n",
      "    accuracy                           0.92       498\n",
      "   macro avg       0.93      0.90      0.91       498\n",
      "weighted avg       0.93      0.92      0.92       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       307\n",
      "           1       0.95      0.81      0.87       191\n",
      "\n",
      "    accuracy                           0.91       498\n",
      "   macro avg       0.92      0.89      0.90       498\n",
      "weighted avg       0.91      0.91      0.91       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       307\n",
      "           1       0.94      0.78      0.85       191\n",
      "\n",
      "    accuracy                           0.90       498\n",
      "   macro avg       0.91      0.88      0.89       498\n",
      "weighted avg       0.90      0.90      0.90       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       307\n",
      "           1       0.93      0.75      0.83       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.90      0.86      0.87       498\n",
      "weighted avg       0.89      0.88      0.88       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 7 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       307\n",
      "           1       0.93      0.75      0.83       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.90      0.86      0.87       498\n",
      "weighted avg       0.89      0.88      0.88       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       307\n",
      "           1       0.92      0.72      0.81       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.88      0.84      0.86       498\n",
      "weighted avg       0.88      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89       307\n",
      "           1       0.91      0.70      0.79       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.83      0.84       498\n",
      "weighted avg       0.87      0.86      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       307\n",
      "           1       0.91      0.71      0.80       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.88      0.83      0.85       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       307\n",
      "           1       0.92      0.68      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.82      0.84       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       307\n",
      "           1       0.92      0.70      0.79       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.88      0.83      0.84       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88       307\n",
      "           1       0.90      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.89      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88       307\n",
      "           1       0.89      0.64      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       307\n",
      "           1       0.89      0.62      0.73       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.80       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.88      0.63      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.79      0.80       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.88      0.65      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.89      0.64      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.88       307\n",
      "           1       0.87      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.84      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.88      0.65      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 7 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       307\n",
      "           1       0.84      0.65      0.73       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.82      0.79      0.80       498\n",
      "weighted avg       0.82      0.82      0.81       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       307\n",
      "           1       0.94      0.76      0.84       191\n",
      "\n",
      "    accuracy                           0.89       498\n",
      "   macro avg       0.91      0.87      0.88       498\n",
      "weighted avg       0.90      0.89      0.89       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       307\n",
      "           1       0.92      0.75      0.82       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.89      0.85      0.87       498\n",
      "weighted avg       0.88      0.88      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       307\n",
      "           1       0.93      0.72      0.81       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.89      0.84      0.86       498\n",
      "weighted avg       0.88      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91       307\n",
      "           1       0.93      0.73      0.82       191\n",
      "\n",
      "    accuracy                           0.88       498\n",
      "   macro avg       0.89      0.85      0.86       498\n",
      "weighted avg       0.88      0.88      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       307\n",
      "           1       0.91      0.71      0.80       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.88      0.83      0.85       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       307\n",
      "           1       0.92      0.70      0.79       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.88      0.83      0.84       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 6 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       307\n",
      "           1       0.90      0.71      0.79       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.83      0.84       498\n",
      "weighted avg       0.86      0.86      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       307\n",
      "           1       0.89      0.70      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.84       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       307\n",
      "           1       0.89      0.70      0.79       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.84       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.89      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.89      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.80      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.85      0.67      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       307\n",
      "           1       0.87      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88       307\n",
      "           1       0.87      0.69      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       307\n",
      "           1       0.85      0.69      0.76       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.86      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       307\n",
      "           1       0.85      0.69      0.76       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.81      0.82       498\n",
      "weighted avg       0.83      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 6 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       307\n",
      "           1       0.81      0.69      0.75       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.82      0.80      0.80       498\n",
      "weighted avg       0.82      0.82      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       307\n",
      "           1       0.93      0.72      0.81       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.89      0.84      0.85       498\n",
      "weighted avg       0.88      0.87      0.87       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90       307\n",
      "           1       0.92      0.71      0.80       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.88      0.83      0.85       498\n",
      "weighted avg       0.87      0.86      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90       307\n",
      "           1       0.93      0.70      0.80       191\n",
      "\n",
      "    accuracy                           0.87       498\n",
      "   macro avg       0.88      0.83      0.85       498\n",
      "weighted avg       0.87      0.87      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       307\n",
      "           1       0.90      0.71      0.80       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.87      0.83      0.84       498\n",
      "weighted avg       0.86      0.86      0.86       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       307\n",
      "           1       0.90      0.70      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.82      0.84       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88       307\n",
      "           1       0.90      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       307\n",
      "           1       0.87      0.69      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.83       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.90      0.66      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 5 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.90      0.66      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       307\n",
      "           1       0.91      0.64      0.75       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.80      0.82       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       307\n",
      "           1       0.90      0.68      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.81      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       307\n",
      "           1       0.90      0.64      0.75       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.80      0.82       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.86      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.84      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       307\n",
      "           1       0.90      0.62      0.73       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.80       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.88       307\n",
      "           1       0.87      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       307\n",
      "           1       0.90      0.63      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88       307\n",
      "           1       0.86      0.69      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.84      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88       307\n",
      "           1       0.90      0.64      0.75       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88       307\n",
      "           1       0.92      0.62      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.86      0.79      0.81       498\n",
      "weighted avg       0.85      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 5 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       307\n",
      "           1       0.84      0.70      0.76       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.83      0.81      0.81       498\n",
      "weighted avg       0.83      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       307\n",
      "           1       0.90      0.68      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.82      0.83       498\n",
      "weighted avg       0.86      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       307\n",
      "           1       0.86      0.72      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.85      0.82      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89       307\n",
      "           1       0.90      0.69      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.82      0.83       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       307\n",
      "           1       0.88      0.69      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88       307\n",
      "           1       0.89      0.69      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.83       498\n",
      "weighted avg       0.85      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89       307\n",
      "           1       0.93      0.68      0.78       191\n",
      "\n",
      "    accuracy                           0.86       498\n",
      "   macro avg       0.88      0.82      0.84       498\n",
      "weighted avg       0.87      0.86      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       307\n",
      "           1       0.89      0.70      0.78       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.84       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88       307\n",
      "           1       0.86      0.70      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.82      0.83       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88       307\n",
      "           1       0.90      0.64      0.75       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.89      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 4 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       307\n",
      "           1       0.89      0.70      0.79       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.86      0.82      0.84       498\n",
      "weighted avg       0.86      0.85      0.85       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.88       307\n",
      "           1       0.87      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.84      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.87      0.64      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.79      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87       307\n",
      "           1       0.84      0.68      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.83      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.89       307\n",
      "           1       0.91      0.66      0.77       191\n",
      "\n",
      "    accuracy                           0.85       498\n",
      "   macro avg       0.87      0.81      0.83       498\n",
      "weighted avg       0.86      0.85      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87       307\n",
      "           1       0.88      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       307\n",
      "           1       0.89      0.62      0.73       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.80       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       307\n",
      "           1       0.85      0.69      0.76       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.81      0.82       498\n",
      "weighted avg       0.83      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87       307\n",
      "           1       0.88      0.65      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 4 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       307\n",
      "           1       0.83      0.70      0.76       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.83      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       307\n",
      "           1       0.85      0.71      0.77       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.84      0.82      0.83       498\n",
      "weighted avg       0.84      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87       307\n",
      "           1       0.84      0.68      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.83      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.68      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.84      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.88       307\n",
      "           1       0.84      0.72      0.78       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.84      0.82      0.83       498\n",
      "weighted avg       0.84      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       307\n",
      "           1       0.89      0.66      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.86      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.84       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87       307\n",
      "           1       0.88      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       307\n",
      "           1       0.86      0.65      0.74       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.83      0.79      0.80       498\n",
      "weighted avg       0.83      0.82      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       307\n",
      "           1       0.88      0.67      0.76       191\n",
      "\n",
      "    accuracy                           0.84       498\n",
      "   macro avg       0.85      0.81      0.82       498\n",
      "weighted avg       0.85      0.84      0.83       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       307\n",
      "           1       0.90      0.63      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.88      0.64      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.80      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       307\n",
      "           1       0.90      0.61      0.73       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.80       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.88      0.64      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 3 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       307\n",
      "           1       0.86      0.65      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.83      0.79      0.80       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       307\n",
      "           1       0.89      0.63      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.80       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       307\n",
      "           1       0.80      0.69      0.74       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.81      0.79      0.80       498\n",
      "weighted avg       0.82      0.82      0.81       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87       307\n",
      "           1       0.90      0.63      0.74       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.85      0.79      0.81       498\n",
      "weighted avg       0.84      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87       307\n",
      "           1       0.90      0.61      0.73       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.85      0.78      0.80       498\n",
      "weighted avg       0.84      0.82      0.81       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.86      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       307\n",
      "           1       0.86      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.84      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 3 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       307\n",
      "           1       0.79      0.70      0.74       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.81      0.79      0.80       498\n",
      "weighted avg       0.81      0.81      0.81       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86       307\n",
      "           1       0.86      0.59      0.70       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.83      0.77      0.78       498\n",
      "weighted avg       0.82      0.81      0.80       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87       307\n",
      "           1       0.85      0.66      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.83      0.80      0.81       498\n",
      "weighted avg       0.83      0.83      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.96      0.86       307\n",
      "           1       0.91      0.57      0.70       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.84      0.76      0.78       498\n",
      "weighted avg       0.83      0.81      0.80       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86       307\n",
      "           1       0.85      0.63      0.72       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.82      0.78      0.79       498\n",
      "weighted avg       0.82      0.82      0.81       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86       307\n",
      "           1       0.85      0.63      0.72       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.82      0.78      0.79       498\n",
      "weighted avg       0.82      0.82      0.81       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.93      0.85       307\n",
      "           1       0.84      0.59      0.69       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.81      0.76      0.77       498\n",
      "weighted avg       0.81      0.80      0.79       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       307\n",
      "           1       0.84      0.66      0.74       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.83      0.79      0.80       498\n",
      "weighted avg       0.82      0.82      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85       307\n",
      "           1       0.86      0.55      0.68       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.82      0.75      0.76       498\n",
      "weighted avg       0.81      0.80      0.78       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.97      0.86       307\n",
      "           1       0.92      0.52      0.67       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.84      0.75      0.76       498\n",
      "weighted avg       0.82      0.80      0.78       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.86       307\n",
      "           1       0.84      0.65      0.74       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.83      0.79      0.80       498\n",
      "weighted avg       0.82      0.82      0.82       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85       307\n",
      "           1       0.86      0.55      0.68       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.82      0.75      0.76       498\n",
      "weighted avg       0.81      0.80      0.78       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85       307\n",
      "           1       0.86      0.57      0.68       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.82      0.75      0.77       498\n",
      "weighted avg       0.81      0.80      0.79       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85       307\n",
      "           1       0.80      0.65      0.72       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.80      0.78      0.79       498\n",
      "weighted avg       0.80      0.81      0.80       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86       307\n",
      "           1       0.88      0.55      0.68       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.83      0.75      0.77       498\n",
      "weighted avg       0.82      0.80      0.79       498\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest with max depth of 2 and sample leaves 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86       307\n",
      "           1       0.85      0.61      0.71       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.82      0.77      0.79       498\n",
      "weighted avg       0.82      0.81      0.80       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.85       307\n",
      "           1       0.89      0.54      0.68       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.83      0.75      0.76       498\n",
      "weighted avg       0.82      0.80      0.79       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86       307\n",
      "           1       0.84      0.63      0.72       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.82      0.78      0.79       498\n",
      "weighted avg       0.82      0.81      0.81       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86       307\n",
      "           1       0.85      0.63      0.73       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.83      0.78      0.79       498\n",
      "weighted avg       0.82      0.82      0.81       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84       307\n",
      "           1       0.82      0.57      0.67       191\n",
      "\n",
      "    accuracy                           0.79       498\n",
      "   macro avg       0.80      0.74      0.75       498\n",
      "weighted avg       0.79      0.79      0.77       498\n",
      "\n",
      "\n",
      "Forest with max depth of 2 and sample leaves 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.86       307\n",
      "           1       0.85      0.64      0.73       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.83      0.79      0.80       498\n",
      "weighted avg       0.82      0.82      0.81       498\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20,1, -1):\n",
    "    for n in range(1, 21):\n",
    "        # Make the model\n",
    "        forest = RandomForestClassifier(max_depth=i, min_samples_leaf=n)#, random_state=123)\n",
    "\n",
    "        #why isn't the random_state argument working?\n",
    "\n",
    "        # Fit the model (on train and only train)\n",
    "        forest.fit(X_train, y_train)\n",
    "\n",
    "        # Use the model\n",
    "        # We'll evaluate the model's performance on train, first\n",
    "        y_predictions = forest.predict(X_train)\n",
    "\n",
    "        # Produce the classification report on the actual y values and this model's predicted y values\n",
    "        report = classification_report(y_train, y_predictions) #, output_dict=True)\n",
    "        print(f\"Forest with max depth of {i} and sample leaves {n}\")\n",
    "        print(report)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f82ab",
   "metadata": {},
   "source": [
    "- see about altering the for loop to just return accuracy, leaves and depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf45b856",
   "metadata": {},
   "source": [
    "### 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2b183fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.827103</td>\n",
       "      <td>0.168881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.923695</td>\n",
       "      <td>0.817757</td>\n",
       "      <td>0.105938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.905622</td>\n",
       "      <td>0.831776</td>\n",
       "      <td>0.073847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.887550</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.088485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.883534</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.093815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.019442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.803213</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.036858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.787149</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.025466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.803213</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.032185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.797189</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.035507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_depth  min_leaves  train_accuracy  validate_accuracy  difference\n",
       "0           20           1        0.995984           0.827103    0.168881\n",
       "1           20           2        0.923695           0.817757    0.105938\n",
       "2           20           3        0.905622           0.831776    0.073847\n",
       "3           20           4        0.887550           0.799065    0.088485\n",
       "4           20           5        0.883534           0.789720    0.093815\n",
       "..         ...         ...             ...                ...         ...\n",
       "375          2          16        0.781124           0.761682    0.019442\n",
       "376          2          17        0.803213           0.766355    0.036858\n",
       "377          2          18        0.787149           0.761682    0.025466\n",
       "378          2          19        0.803213           0.771028    0.032185\n",
       "379          2          20        0.797189           0.761682    0.035507\n",
       "\n",
       "[380 rows x 5 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attempting to create lists that i can pack into a DF for easy comparison below\n",
    "# create an empty list to fill in the for loop\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for i in range(20,1, -1):\n",
    "    for n in range(1, 21):\n",
    "        # Make the model\n",
    "        forest = RandomForestClassifier(max_depth=i, min_samples_leaf=n)#, random_state=123)\n",
    "\n",
    "        #why isn't the random_state argument working?\n",
    "\n",
    "        # Fit the model (on train and only train)\n",
    "        forest.fit(X_train, y_train)\n",
    "\n",
    "        # Use the model\n",
    "        # We'll evaluate the model's performance on train, first\n",
    "        in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "        out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "        output = {\n",
    "            \"max_depth\": i,\n",
    "            \"min_leaves\": n,\n",
    "            \"train_accuracy\": in_sample_accuracy,\n",
    "            \"validate_accuracy\": out_of_sample_accuracy\n",
    "        }\n",
    "\n",
    "        metrics.append(output)\n",
    "\n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aa510da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.set_index('max_depth').plot\n",
    "\n",
    "# review ravinder's graph here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1924bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83563348",
   "metadata": {},
   "source": [
    "### 6. After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8c8e7523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_leaves</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.887550</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>0.046429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0.899598</td>\n",
       "      <td>0.836449</td>\n",
       "      <td>0.063150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0.893574</td>\n",
       "      <td>0.831776</td>\n",
       "      <td>0.061799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.831776</td>\n",
       "      <td>0.071839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.905622</td>\n",
       "      <td>0.831776</td>\n",
       "      <td>0.073847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.019442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.787149</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.025466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.797189</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.035507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.059603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.069643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_depth  min_leaves  train_accuracy  validate_accuracy  difference\n",
       "281          6           2        0.887550           0.841121    0.046429\n",
       "42          18           3        0.899598           0.836449    0.063150\n",
       "123         14           4        0.893574           0.831776    0.061799\n",
       "102         15           3        0.903614           0.831776    0.071839\n",
       "2           20           3        0.905622           0.831776    0.073847\n",
       "..         ...         ...             ...                ...         ...\n",
       "375          2          16        0.781124           0.761682    0.019442\n",
       "377          2          18        0.787149           0.761682    0.025466\n",
       "379          2          20        0.797189           0.761682    0.035507\n",
       "359          3          20        0.821285           0.761682    0.059603\n",
       "316          5          17        0.831325           0.761682    0.069643\n",
       "\n",
       "[357 rows x 5 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.difference <= 0.10].sort_values(by=['validate_accuracy', 'difference'], ascending = [False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e7779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
